---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a Ph.D. student at [School of Cyber Science and Engineering](https://cse.whu.edu.cn/), [Wuhan University](https://www.whu.edu.cn/), where I am conducting research in AI Security. I am very fortunate to be advised by [Prof. Qian Wang](https://nisplab.whu.edu.cn/People.htm) of [NIS&P Lab](https://nisplab.whu.edu.cn/index.htm). My works primarily focus on adversarial robustness of AI systems, alignment for large language models, etc. 

Previously, I received the B.E. degree in communication engineering from Shandong University in 2019 and the M.S. degree in electronic information from Wuhan University, China, in 2022.

Contact me at [shenyizhang@whu.edu.cn](mailto:shenyizhang@whu.edu.cn) or [syzhang.whu@gmail.com](mailto:syzhang.whu@gmail.com).


Publications
======
**2025**
* **JBShield: Defending Large Language Models from Jailbreak Attacks through Activated Concept Analysis and Manipulation**  
  **Shenyi Zhang**, Yuchen Zhai, Keyan Guo, Hongxin Hu, Shengnan Guo, Zheng Fang, Lingchen Zhao, Chao Shen, Cong Wang, Qian Wang  
  _USENIX Security Symposium, 2025_  
  [[arxiv]](https://arxiv.org/abs/2502.07557)  [[code]](https://github.com/NISPLab/JBShield)  

**2024**
* **Zero-query Adversarial Attack on Black-box Automatic Speech Recognition Systems**  
  Zheng Fang, Tao Wang, Lingchen Zhao, **Shenyi Zhang**, Bowen Li, Yunjie Ge, Qi Li, Chao Shen, Qian Wang  
  _ACM SIGSAC Conference on Computer and Communications Security (CCS), 2024_  
  [[paper]](https://dl.acm.org/doi/abs/10.1145/3658644.3670309)  [[arxiv]](https://arxiv.org/abs/2406.19311)  
* **Hijacking Attacks against Neural Networks by Analyzing Training Data**  
  Yunjie Ge, Qian Wang, Huayang Huang, Qi Li, Cong Wang, Chao Shen, Lingchen Zhao, Peipei Jiang, Zheng Fang, **Shenyi Zhang**  
  _USENIX Security Symposium, 2024_  
  [[paper]](https://www.usenix.org/conference/usenixsecurity24/presentation/ge-hijacking)  [[arxiv]](https://arxiv.org/abs/2401.09740)  [[code]](https://github.com/NISPLab/CleanSheet/)  
* **Enhancing the Transferability of Adversarial Examples with Noise Injection Augmentation**  
  Yiheng Duan, Yunjie Ge, Zixuan Wang, Jiayi Yu, **Shenyi Zhang**, Libing Wu  
  _IEEE International Conference on Multimedia and Expo (ICME), 2024_  
  [[paper]](https://ieeexplore.ieee.org/abstract/document/10688210)  
* **Perception-driven Imperceptible Adversarial Attack against Decision-based Black-box Models**  
  **Shenyi Zhang**, Baolin Zheng, Peipei Jiang, Lingchen Zhao, Chao Shen, Qian Wang  
  _IEEE Transactions on Information Forensics and Security (TIFS), 2024_  
  [[paper]](https://ieeexplore.ieee.org/abstract/document/10415445)  [[code]](https://github.com/syzhangcodes/ImperceptibleAttack)  

**2021**
* **Black-box Adversarial Attacks on Commercial Speech Platforms with Minimal Information**   
  Baolin Zheng, Peipei Jiang, Qian Wang, Qi Li, Chao Shen, Cong Wang, Yunjie Ge, Qingyang Teng, **Shenyi Zhang**  
  _ACM SIGSAC Conference on Computer and Communications Security (CCS), 2021_   
  [[paper]](https://dl.acm.org/doi/abs/10.1145/3460120.3485383)  [[arxiv]](https://arxiv.org/abs/2110.09714)  


Services
======
* Reviewer
  * IEEE Transactions on Information Forensics and Security (TIFS)
  * IEEE Transactions on Emerging Topics in Computing (TETC)
  * ACM Transactions on Cyber-Physical Systems (TCPS)
  * ACM Transactions on Internet Technology (TOIT)
  * Neurocomputing
  * ACM MM 2025
  * IEEE ICME 2024, 2025
  * IJCNN 2025


Projects
======
* [NewAdversarialAttackPaper](https://github.com/daksim/NewAdversarialAttackPaper): A list of recent adversarial attack and defense papers (including those on large language models).
* [Imagenet-1K-Formatter](https://github.com/daksim/Imagenet-1K-Formatter): Reorganizing the ImageNet-1k dataset into the standard directory structure.
